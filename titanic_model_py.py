# -*- coding: utf-8 -*-
"""titanic_model.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ixVUXp-ZtUNwdMXqn3045PeQolN60Nt9
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# --- Load ---
df = pd.read_csv("train.csv")

# --- Quick overview ---
print(df.shape)
print(df.head(3))
df.info()

# --- Minimal cleaning ---
df["Age"] = df["Age"].fillna(df["Age"].median())
df["Embarked"] = df["Embarked"].fillna(df["Embarked"].mode()[0])

# --- Three simple insights ---
avg_age = df["Age"].mean()
survival_rate = df["Survived"].mean() * 100
surv_by_sex = df.groupby("Sex")["Survived"].mean() * 100

print(f"Average age: {avg_age:.1f}")
print(f"Overall survival rate: {survival_rate:.1f}%")
print("Survival rate by sex (%):")
print(surv_by_sex.round(1))

# --- One simple chart ---
surv_by_sex.plot(kind="bar")
plt.title("Titanic: Survival Rate by Sex")
plt.ylabel("Survival Rate (%)")
plt.show()

# --- Very simple model: Logistic Regression ---
features = ["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]
X = pd.get_dummies(df[features], drop_first=True)  # encode categorical
y = df["Survived"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
pred = model.predict(X_test)

print("Accuracy:", round(accuracy_score(y_test, pred), 3))
print(classification_report(y_test, pred))